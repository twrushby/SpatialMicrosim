---
title: "Spatial Microsim example"
author: "Thomas W Rushby"
date: "13/10/2017"
output:
  html_document:
    fig_caption: yes
    keep_md: yes
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# About

This document was created to record the code and output of the example spatial microsimulation in Robin Lovelace's book Spatial microsimulation with R <http://robinlovelace.net/spatial-microsim-book/>. The text quotes heavily from the book and care should be taken when using any of the text to correctly cite the source.

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

# Introduction

## Why use spatial microsim?

"Spatial Microsimulation is useful when you have an intermediary amount of data available: geographically aggregated count and a non-spatial survey." Lovelace - Spatial microsimulaton with R

\newpage

# Microsim example

## Load data

```{r load_ind_data}
### Load the individual level data

ind <- read.csv("Data/SimpleWorld/ind-full.csv") # load the individual level data

class(ind) # verify the data type
ind
```

We can see from the output above that this has loaded a data frame object with `r nrow(ind)` rows and `r ncol(ind)` columns.

```{r load_constraint_data}
### Load the constraint data (usually one variable at a time - individual files)

con_age <- read.csv("Data/SimpleWorld/age.csv")
con_sex <- read.csv("Data/SimpleWorld/sex.csv")

class(con_age)
class(con_sex)

con_age
con_sex
```

## Check and re-format data

### Tests for constraint variables

Beware of constraint variables that come from different sources (Lovelace):
* check coherence of data
* in some cases the total number of individuals will be inconsistent
* can happen if constraint variables are measured using different base populations or at different levels (i.e indivdual and household)
This can cause the procedure to fail.

So, test constraints . . .

1. Zone ordering
Check that zones are loaded in the same order - and with some kind of zone_id that identifies each zone (consistent across datasets/constraint variables)
2. Total population
Indicates the same population base
3. Row totals
Indicating that the zones are listed in the same order (check on zone_ids) and the same population base

```{r constraint_tests}
sum(con_age) == sum(con_sex) # check population totals

rowSums(con_age) == rowSums(con_sex) # check row totals
```

### Subset and filter

Good practice to filter out all unwanted data early on (i.e. remove superfluous variables). This will speed-up simulation and avoid over-complication.

In the ind dataset, only age and sex variables are useful so we remove income:

```{r subset_and_filter, include=TRUE}

ind_orig <- ind # keep original dataset
ind <- ind[, -4] # removes income (column 4)
ind
```

### Recategorise individual level variables

Ensure each dataset contains the same information.

In this example we need to categorise age in the ind dataset to match the constraint data (con_age).

```{r recategorise_ind_variables}

# categorise (bin) the age variable
brks <- c(0,49,120) # set break points
labs <- c("a0_49", "a50+") # create labels
ind$age <- cut(ind$age, breaks = brks, labels = labs) # overwrite the age variable with categorical age bands
ind
```

### Match individual and aggregate level data names

```{r match_data_names}
levels(ind$age) # what are the levels in individual age variable?

names(con_age) # what are the column names (= age levels) in the aggregate age constraint variable

names(con_age) <- levels(ind$age) # rename aggregate age constraint variables
```

### Create constraint object

Now all constraint variable names match the individual data we combine them into a single object.

```{r combine_constraints}

cons <- cbind(con_age, con_sex) # column bind, cols are constraints - rows are zones

cons[1:2, ] # display constraints for first two zones (rows)
```
We now have two objects for the individual and aggregate datasets:

* Individual - with dimensions (`r dim(ind)`) - 5 individuals, 3 variables
* Constraints - with dimensions (`r dim(cons)`) - 3 zones, 4 variables (2 variables with 2categories each)

### Make individual and constraint objects comparable

In order to compare the two datasets we must 'flatten' the individual level data - increasing the width so each column becomes one category name (and thus matching format of constraints data).

**Note: great care should be taken to format columns in the same order as aggregate (constraints) data** - unexpected results may occur where there are errors here. Be warned!

```{r flatten_ind_data}

cat_age <- model.matrix(~ ind$age - 1)
cat_sex <- model.matrix(~ ind$sex - 1)[, c(2, 1)] # square brackets changes column order (to match constraints dataset)

(ind_cat <-  cbind(cat_age, cat_sex)) # combine into single data frame - brackets used to print result

(colSums(ind_cat)) # view the aggregated version of ind (and print)
ind_agg <- colSums(ind_cat) # save result

# test compatability of ind_agg and cons 
(rbind(cons[1,], ind_agg)) # by binding into single data frame (uses only first row of cons)
```

## Population synthesis

Now that we have the data loaded and prepared this part is concerned with running a spatial microsimulation model using iterative proportional fitting (IPF). IPF is used to allocate individuals to zones.

> How representative each individual is of each zone is represented by their *weight* for that zone.
> The number of weights is therefore equal to the number of zones multiplied by the number of individuals in the microdata.

We have `r nrow(cons)` rows and `r nrow(ind)` individuals in the SimpleWorld data, therefore `r nrow(cons) * nrow(ind)` weights will be estmiated in this example.

**note: creating matrix to hold weights appears here in book (printed pdf) but logically comes later - see weighting algorithms\ipf below**

## Weighting algorithms

There are *deterministic* and *stochastic* methods for weighting in spatial microsimulation. IPF is *deterministic* and therefore the results never vary: the weights will be the same every time. In contrast, *stochastic* methods use random numbers.

The distinction between *deterministic* and *stochastic* approaches points to a wider divide in methods: *reweighting* and *combinatorial optimisation*.

> The conecpt of weights is critical to understanding how population synthesis generates spatial microdata.

### Random allocation

If we have no information on the characteristics of the inhabitants, only total population of each zone then we can only assume that the distribution of characteristics found in the sample is representative of the distribution of the whole population. In this scenario, individuals are chosen at random from the sample and allocated to zones at random. Here, the distribution of characteristics of individuals in each zone will tend towards the microdata (see Lovelace, p.41).

In SimpleWorld this can be achieved by randomly allocating the 5 individuals of the microdata to zone 1 (with population of 12) using the `sample()` command:

```{r random_allocation}

set.seed(1) # set seed for reproducibility
sel <- sample(x = 5, size = 12, replace = T) # create selection - sample uses a randmo number generator
ind_z1 <- ind_orig[sel, ]
head(ind_z1,3 )

```

Changing the seed in the code above changes the individuals that are selected (try it).

### IPF

IPF is the most widely used and mature *deterministic* method to allocate individuals to zones (p.43).

> IPF invoves calculating a series of non-integer weights that represent how representative each individual is of each zone. This is reweighting. 

Three steps:

1. generate a weight matrix containing fractional numbers
2. integerisation - number of times each individual needs to be replicated (grossing up?)
3. expansion - calculation of the final dataset

#### Create a matrix to hold weights

First, we create a matrix and initially populate with 1s. The weights matrix links the individual data to he aggregate level. Therefore every individual in this table is currently equally representative of every zone.

A value of zero in cell `[i,j]` indicates that an individual `i` is not representative of a zone `j`.

```{r create_weights_matrix}

weights <- matrix(data = 1, nrow = nrow(ind), ncol = nrow(cons)) # create matrix for weights - set values as 1
(dim(weights))
weights
```

During the IPF procedure, the weights in this matrix are iteratively updated until they converge towards a single result.

#### IPFinR

IPFinR begins with a couple of nested loops, one to iterate through each zone (1:n_zone) and one to iterate through each category within the contraints (0-49 and 50+ in the first constraint, age).

```{r IPFinR}

# create intuitive names for totals
n_zone <- nrow(cons) # number of zones
n_ind <- nrow(ind) # number of individuals
n_age <- ncol(con_age) #  number of categories of "age"
n_sex <- ncol(con_sex) # number of categories of "sex"

# create initial matrix of categorical counts from ind
# rows are zones and columns different categories of the variables
ind_agg0 <- t(apply(cons, 1, function(x) 1 *ind_agg))
colnames(ind_agg0) <- names(cons)
# duplicate the weight matrix to keep in memory each step
weights1 <- weights2 <- weights # create additional weight objects - all still populated with 1s at this stage

# Assign values to the previously created weight matrix
# to adapt to age constraint
for (j in 1:n_zone){
  for (i in 1:n_age){
    index <- ind_cat[, i] == 1
    weights1[index, j] <- weights[index, j] * con_age[j,i] / ind_agg0[j,i]
  }
  print(weights1)
}
```

To see weights that have been allocated to individuals to populate zone 2 we query the second column, giving the result:

`r weights1[,2]`

To see the weight allocated to individual 3 for each zone we query the third row of the weight matrix:

`r weights1[3,]`

Note: we ask R to write the result after each completing each zone. The algorithm proceeds zone by zone with each column of the matrix corresponding to a zone.
Note also that weights generated are fractional.

The next step is to re-aggregate the results from individual level after reweighting.
The weights of zone 1 (1st column of `weights1`) is multiplied by the characteristics of each individual (held in `ind_cat`). The result is a vector - the values corresponding to the number of people in each category for zone 1. To aggregate all individuals for zone 1, we sum the values in each category.

The following loop re-aggregates the individual level data with the new weights for each zone:

```{r re-aggregate individual level results}

ind_agg2 <- ind_agg1 <- ind_agg0 * NA # create additional ind_agg objects

# assign values to the aggregated data after constraint 1 - age
for(i in 1:n_zone){
  ind_agg1[i,] <- colSums(ind_cat * weights1[,i])
}

print(ind_agg1)
```

#### Preliminary checks to ensure code is working correctly.

1. Are the resulting populations for each zone correct?

```{r IPFinR_prelim_checks1}

# Check populations for first constraint variable - age (columns 1:2)
rowSums(ind_agg1[,1:2]) # simulated populations in each zone - age constraint only
rowSums(cons[,1:2]) # the observed populations in each zone

# Check populations for second constraint - sex (columns 3:4)
rowSums(ind_agg1[,3:4]) # simulated populations in each zone - sex constraint
rowSums(cons[,3:4]) # the observed populations in each zone

```
2. What is the fit between observed and simulated results after constraining by age?

We calculate the correlation between aggregate actual data and the constraints. Produces a value between -1 and 1.
A value (in this example) of 1 will be perfect correlation.

```{r IPFinR_prelim_checks2}

# test fit using cor function
# a 1d representation of the aggregate level data

vec <- function(x) as.numeric(as.matrix(x))
cor(vec(ind_agg0), vec(cons)) # before reweighting (ind_agg0)
cor(vec(ind_agg1), vec(cons)) # after reweighting using age constraint (ind_agg1)
```
We can see from the results above that the new weights lead to a much better fit.

#### Add second constraint variable

```{r second_constraint}

for(j in 1:n_zone){
  for(i in 1:n_sex + n_age){
    index <- ind_cat[,i] == 1
    weights2[index,j] <- weights1[index,j] * cons[j,i] / ind_agg1[j,i]
  }
  print(weights2)
}

# re-aggregate the individual level data with the new weights for each zone
# assign values to the aggregated data after constraint 2 - sex
for(i in 1:n_zone){
  ind_agg2[i,] <- colSums(ind_cat * weights2[,i])
}

print(ind_agg2)

# as before, test fit using cor function

cor(vec(ind_agg0), vec(cons)) # before reweighting (ind_agg0)
cor(vec(ind_agg1), vec(cons)) # after reweighting using age constraint (ind_agg1) - first iteration
cor(vec(ind_agg2), vec(cons)) # after reweighting using sex constraint (ind_agg2) - first iteration

```


# Plots

You can also embed plots, for example:

```{r plots, echo=FALSE}

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
